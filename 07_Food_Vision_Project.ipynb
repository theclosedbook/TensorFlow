{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHINbvrMmgsuOrvdQiiPOL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theclosedbook/TensorFlow/blob/main/07_Food_Vision_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 07 Milestone Project 1:  Food Vision Big™\n",
        "In the previous notebook (transfer learning part 3: scaling up) we built Food Vision mini: a transfer learning model which beat the original results of the Food101 paper with only 10% of the data.\n",
        "\n",
        "But you might be wondering, what would happen if we used all the data?\n",
        "\n",
        "Well, that's what we're going to find out in this notebook!\n",
        "\n",
        "We're going to be building Food Vision Big™, using all of the data from the Food101 dataset.\n",
        "\n",
        "Yep. All 75,750 training images and 25,250 testing images.\n",
        "\n",
        "And guess what...\n",
        "\n",
        "This time we've got the goal of beating DeepFood, a 2016 paper which used a Convolutional Neural Network trained for 2-3 days to achieve 77.4% top-1 accuracy.\n",
        "\n",
        "Note: Top-1 accuracy means \"accuracy for the top softmax activation value output by the model\" (because softmax ouputs a value for every class, but top-1 means only the highest one is evaluated). Top-5 accuracy means \"accuracy for the top 5 softmax activation values output by the model\", in other words, did the true label appear in the top 5 activation values? Top-5 accuracy scores are usually noticeably higher than top-1.\n",
        "\n",
        "Food Vision Big Food Vision mini\n",
        "Dataset source\tTensorFlow Datasets\tPreprocessed download from Kaggle\n",
        "Train data\t75,750 images\t7,575 images\n",
        "Test data\t25,250 images\t25,250 images\n",
        "Mixed precision\tYes\tNo\n",
        "Data loading\tPerformanant tf.data API\tTensorFlow pre-built function\n",
        "Target results\t77.4% top-1 accuracy (beat DeepFood paper)\t50.76% top-1 accuracy (beat Food101 paper)\n",
        "Table comparing difference between Food Vision Big (this notebook) versus Food Vision mini (previous notebook).\n",
        "\n",
        "Alongside attempting to beat the DeepFood paper, we're going to learn about two methods to significantly improve the speed of our model training:\n",
        "\n",
        "Prefetching\n",
        "Mixed precision training\n",
        "But more on these later.\n",
        "\n",
        "What we're going to cover\n",
        "Using TensorFlow Datasets to download and explore data\n",
        "Creating preprocessing function for our data\n",
        "Batching & preparing datasets for modelling (making our datasets run fast)\n",
        "Creating modelling callbacks\n",
        "Setting up mixed precision training\n",
        "Building a feature extraction model (see transfer learning part 1: feature extraction)\n",
        "Fine-tuning the feature extraction model (see transfer learning part 2: fine-tuning)\n",
        "Viewing training results on TensorBoard\n",
        "How you should approach this notebook\n",
        "You can read through the descriptions and the code (it should all run, except for the cells which error on purpose), but there's a better option.\n",
        "\n",
        "Write all of the code yourself.\n",
        "\n",
        "Yes. I'm serious. Create a new notebook, and rewrite each line by yourself. Investigate it, see if you can break it, why does it break?\n",
        "\n",
        "You don't have to write the text descriptions but writing the code yourself is a great way to get hands-on experience.\n",
        "\n",
        "Don't worry if you make mistakes, we all do. The way to get better and make less mistakes is to write more code.\n",
        "\n",
        "We're going to be using mixed precision training.\n",
        "\n",
        "Mixed precision training was introduced in TensorFlow 2.4.0 (a very new feature at the time of writing).\n",
        "\n",
        "What does mixed precision training do?\n",
        "\n",
        "Mixed precision training uses a combination of single precision (float32) and half-preicison (float16) data types to speed up model training (up 3x on modern GPUs).\n",
        "\n",
        "We'll talk about this more later on but in the meantime you can read the TensorFlow documentation on mixed precision for more details.\n",
        "\n",
        "For now, before we can move forward if we want to use mixed precision training, we need to make sure the GPU powering our Google Colab instance (if you're using Google Colab) is compataible.\n",
        "\n",
        "For mixed precision training to work, you need access to a GPU with a compute compability score of 7.0+."
      ],
      "metadata": {
        "id": "qIrINmnsIMET"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i7UT9JZlIgxX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}