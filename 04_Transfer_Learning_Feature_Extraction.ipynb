{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQTCAsaJfnvzuoLgaQOv4E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theclosedbook/TensorFlow/blob/main/04_Transfer_Learning_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with TensorFlow Part 1 : Feature Extraction\n",
        "\n",
        "Transfer learning is leveraging a working model's existing architecture and learned patterns for our own problem.\n",
        "There are two main benefits:\n",
        "\n",
        "1. Can leverage an existing neural network arechitecture proven to work on problems similar to our own.\n",
        "2. Can leverage a working neural network architecture whi9ch has already learned patterns on similar data to our own, then we can adapt those patterns to our own data."
      ],
      "metadata": {
        "id": "0I-SY45hFPcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Are we using a GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYNu-gmxKT5T",
        "outputId": "6a3237bd-a611-4550-9ec9-ddd1d8e6577a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Feb 12 15:14:05 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downlaod and become one with the data"
      ],
      "metadata": {
        "id": "JUpuyrRuKgxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data\n",
        "import zipfile\n",
        "\n",
        "# Downlaod the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZpKrMjvKpCd",
        "outputId": "54a741c1-d72f-4c4b-dc54-6654b28d682a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-12 16:41:58--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.130.207, 74.125.68.207, 64.233.170.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.130.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  21.9MB/s    in 8.3s    \n",
            "\n",
            "2024-02-12 16:42:06 (19.4 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images in each folder\n",
        "import os\n",
        "\n",
        "# Walk through the directories\n",
        "for dirpath,dirnames,filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "-GGcYla6LJzF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### creating a dataloader (preparing the data)\n",
        "We'll use `ImageDataGenerator` class to load in our images"
      ],
      "metadata": {
        "id": "jLf1Jqt9Mucg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224,224)\n",
        "BATCH_SIZE=32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training Images:\")\n",
        "train_data_10_precent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size=IMAGE_SHAPE,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode=\"categorical\")\n",
        "\n",
        "print(\"Testing Data:\")\n",
        "\n",
        "test_data_10_percent = test_datagen.flow_from_directory(test_dir,\n",
        "                                                        target_size=IMAGE_SHAPE,\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OB2J14-4653",
        "outputId": "17841d4b-1265-42df-a06b-39bb1473a9cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing Data:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up callbacks(things to run whilst our model train)\n",
        "\n",
        "Callbacks are extra functionallity you can add to your models to be performed during or after training. Some of the most popular callbacks:\n",
        "\n",
        "* Training experiments with the TensorBoard callback.\n",
        "* Model checkpoint with the ModelCheckpoint callback.\n",
        "* Stopping a model from training (before it trains too long and overfits) with the EarlyStopping callback."
      ],
      "metadata": {
        "id": "2VdVX6Np6d3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorBoard callback(functionized becasue we need to create a new one for each model)\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name,experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  print(f\"Saving TensorBoard log files to : {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "1YamrJxK8hNC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow Hub\n",
        "\n",
        "In the past we have used Tensorflow to create our own models layer by layer from scratch.\n",
        "\n",
        "Now we're going to do a similar process, except the majority of our model's layers are going to come from TensorFlow Hub.\n",
        "\n",
        "We can access pretrained models on:https://tfhub.dev/"
      ],
      "metadata": {
        "id": "8kq87HGS9Ujc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets compare the following two models\n",
        "\n",
        "resnet_url = \"https://www.kaggle.com/models/google/resnet-v2/frameworks/TensorFlow2/variations/50-feature-vector/versions/2\"\n",
        "\n",
        "efficientnet_url = \"https://www.kaggle.com/models/tensorflow/efficientnet/frameworks/TensorFlow2/variations/b0-feature-vector/versions/1\""
      ],
      "metadata": {
        "id": "C_DZrfHe_DkT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "VSGA78VOKclL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a create_model() function to create a model from URL\n",
        "\n",
        "def create_model(model_url,num_classes=10):\n",
        "  # Download a pretrained model and save as a keras layer\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable=False,\n",
        "                                           name=\"feature_extraction_layer\",\n",
        "                                           input_shape=IMAGE_SHAPE+(3,)) # Freeze the already learned patterns\n",
        "\n",
        "  # Create our own model\n",
        "  model=tf.keras.Sequential([\n",
        "      feature_extractor_layer,\n",
        "      layers.Dense(num_classes,activation=\"softmax\", name=\"output_layer\")\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Mix5zPtfKxpR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating and tetsing ResNet TensorFlow Hub Feature Extraction model"
      ],
      "metadata": {
        "id": "NGt_P_B6MEbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Resnet model\n",
        "\n",
        "resnet_model = create_model(resnet_url,\n",
        "                            num_classes=train_data_10_precent.num_classes)"
      ],
      "metadata": {
        "id": "1JRY9EcqL_3s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itk-cwXZMaDN",
        "outputId": "ab1b21df-dff4-4db1-dec4-8f7813972943"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extraction_layer (  (None, 2048)              23564800  \n",
            " KerasLayer)                                                     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23585290 (89.97 MB)\n",
            "Trainable params: 20490 (80.04 KB)\n",
            "Non-trainable params: 23564800 (89.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "resnet_model.compile(loss=\"categorical_crossentropy\",\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "DePST9npM3Ad"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit our model\n",
        "resnet_history = resnet_model.fit(train_data_10_precent,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data_10_precent),\n",
        "                                  validation_data=test_data_10_percent,\n",
        "                                  validation_steps=len(test_data_10_percent),\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                                                         experiment_name=\"resnet50V2\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMcymw_ENL4m",
        "outputId": "56b0ac07-527e-4d36-8ec8-0f4532d786f5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to : tensorflow_hub/resnet50V2/20240212-165626\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 11s 455ms/step - loss: 0.2553 - accuracy: 0.9587 - val_loss: 0.6359 - val_accuracy: 0.8008\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 13s 547ms/step - loss: 0.2140 - accuracy: 0.9680 - val_loss: 0.6335 - val_accuracy: 0.7920\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 12s 494ms/step - loss: 0.1914 - accuracy: 0.9760 - val_loss: 0.6330 - val_accuracy: 0.7944\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 11s 477ms/step - loss: 0.1607 - accuracy: 0.9853 - val_loss: 0.6225 - val_accuracy: 0.8048\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 11s 459ms/step - loss: 0.1396 - accuracy: 0.9920 - val_loss: 0.6270 - val_accuracy: 0.7968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create afunction for our loss curves\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  loss=history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]"
      ],
      "metadata": {
        "id": "MZUjSjm3NeiK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}